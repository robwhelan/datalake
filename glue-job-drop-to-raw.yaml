AWSTemplateFormatVersion: "2010-09-09"
Description: A job that moves data from the drop zone to the raw zone.
Parameters:
  pProjectName:
    Type: String
    Description: the project Name
  pDatabaseName:
    Type: String
    Description: the glue database created for this dataset
  pTableName:
    Type: String
    Description: the source table for this data.
  pDataPartition:
    Type: String
    Description: the partition for where the file will reside in S3 ... example, "orders"
  pDownstreamBucket:
    Type: String
    Description: the bucket downstream of hte drop zone bucket.
Resources:
  rGlueJobDropToRaw:
    Type: AWS::Glue::Job
    Properties:
      #AllocatedCapacity: Double
      GlueVersion: 1.0
      Command:
        Name: glueetl #default for apache spark jobs
        PythonVersion: 3
        ScriptLocation: s3://datalake-rww/glue-scripts/drop-to-raw-order-items.py
      DefaultArguments:
        "--database_name": !Ref pDatabaseName
        '--table_name': !Ref pTableName
        "--job-bookmark-option": "job-bookmark-enable"
        "--data_partition": !Ref pDataPartition
        "--downstream_bucket": !Ref pDownstreamBucket
      Description: Convert incoming CSV to Parquet.
      Name: !Sub '${pProjectName}-glue-job-drop-to-raw-${pTableName}'
      Role: arn:aws:iam::773548596459:role/AWSGlueAdmin
#TODO: create the trigger that makes drop zone job run hourly.
